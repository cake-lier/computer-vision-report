# Conclusioni

Le tecniche di *representation learning* hanno dimostrato ancora una volta la loro superiorità nel campo del *pattern recognition* rispetto a quelle di estrazione di *feature handcrafted*. I nostri risultati sono corroborati da quelli della *challenge*, dove il primo classificato ha ottenuto un'accuratezza superiore al 90%, utilizzando tecniche più approfondite non pubblicamente disponibili. Il problema, comunque, è tutt'altro che irrisolvibile. I nostri risultati dimostrano ancora una volta che anche modelli il cui addestramento è accessibile a chiunque permettono di ottenere ottimi risultati, ascrivendo questo all'insieme dei problemi che è possibile risolvere mediante tecniche di addestramento automatico.

Per quanto riguarda l'estrazione di *feature handcrafted*, sicuramente successivi tentativi possono focalizzarsi sull'estrazione di migliori e più accurate *feature*. La possibilità di utilizzare modelli per le caratteristiche del volto più precisi, come ad esempio "l'occhio di Yuille" [@eye], permetterebbe di catturare meno pixel che non riguardano il punto saliente di riferimento e perciò di estrarre delle *feature* più precise. Inoltre, si potrebbero sostituire le tecniche utilizzate, come ad esempio il "Canny edge detector" o le operazioni morfologiche di apertura e chiusura, con alcune più nuove, più precise o più robuste al rumore. Si potrebbe anche cercare di sostituire le *feature* estratte con altre simili, ad esempio usando le "shape matrix", i "color moments" o i filtri di Gabor, tenendo conto però delle criticità già evidenziate in precedenza. Si può pensare di effettuare maggior *preprocessing* delle immagini, per uniformarle maggiormente e trattenere quelle che davvero rispettano un determinato standard di qualità. Infine, è possibile utilizzare famiglie di classificatori differenti, approcci alla classificazione differenti o addirittura fornire più risorse di calcolo, così da poter rendere modelli ora inaccessibili a portata di mano.

Per il *representation learning*, invece, lo sforzo può essere fatto in direzione di utilizzare sempre la struttura generica delle "reti siamesi", ma usando come *backbone* degli estrattori di *feature* più precisi e più potenti. Oppure, si può pensare di creare una nuova architettura da zero, sia per quanto riguarda la parte di estrazione, costruibile mediante l'uso di reti "encoder-decoder", sia per quanto riguarda la parte di combinazione di *feature* di diversi estrattori, usando tecniche più recenti come il "global average pooling". Si può tentare di utilizzare l'architettura da noi proposta e modificare l'algoritmo di addestramento, le funzioni di attivazione nei livelli intermedi, il numero di neuroni in quelli "*fully-connected*". Infine, si potrebbe usare l'architettura proposta nel paper "Deep Fusion Siamese Network for Automatic Kinship Verification" [@siamese] chiamata "Deep Triplet Network" in cui, per individuare le relazioni di parentela, vengono utilizzati due parenti alla volta.
